{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA+逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LDA的超参数n_components的最优解为: 14\n",
      "\n",
      "逻辑回归的超参数C的最优解为: 1\n",
      "\n",
      "测试集预测正确率为: 98.75%\n",
      "\n",
      "最优超参数模型的评分为: 1.00\n",
      "\n",
      "测试集的预测分类报告如下所示：\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       0.67      1.00      0.80         2\n",
      "           9       1.00      1.00      1.00         2\n",
      "          10       1.00      1.00      1.00         2\n",
      "          11       1.00      1.00      1.00         2\n",
      "          12       1.00      1.00      1.00         2\n",
      "          13       1.00      1.00      1.00         2\n",
      "          14       1.00      1.00      1.00         2\n",
      "          15       1.00      1.00      1.00         2\n",
      "          16       1.00      1.00      1.00         2\n",
      "          17       1.00      1.00      1.00         2\n",
      "          18       1.00      1.00      1.00         2\n",
      "          19       1.00      0.50      0.67         2\n",
      "          20       1.00      1.00      1.00         2\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       1.00      1.00      1.00         2\n",
      "          23       1.00      1.00      1.00         2\n",
      "          24       1.00      1.00      1.00         2\n",
      "          25       1.00      1.00      1.00         2\n",
      "          26       1.00      1.00      1.00         2\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       1.00      1.00      1.00         2\n",
      "          29       1.00      1.00      1.00         2\n",
      "          30       1.00      1.00      1.00         2\n",
      "          31       1.00      1.00      1.00         2\n",
      "          32       1.00      1.00      1.00         2\n",
      "          33       1.00      1.00      1.00         2\n",
      "          34       1.00      1.00      1.00         2\n",
      "          35       1.00      1.00      1.00         2\n",
      "          36       1.00      1.00      1.00         2\n",
      "          37       1.00      1.00      1.00         2\n",
      "          38       1.00      1.00      1.00         2\n",
      "          39       1.00      1.00      1.00         2\n",
      "          40       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.99        80\n",
      "   macro avg       0.99      0.99      0.99        80\n",
      "weighted avg       0.99      0.99      0.99        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def img2vector(filename):\n",
    "    img = mpimg.imread(filename) \n",
    "    return img.reshape(1, -1)\n",
    "\n",
    "X = np.zeros((400,10304),dtype = int)\n",
    "Y = np.zeros(400,dtype = int)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(1,41):\n",
    "    for j in range(1,9):\n",
    "        src = 'C:\\\\Users\\\\93508\\\\Desktop\\\\ORL\\\\s'\n",
    "        src += str(i)\n",
    "        src += '\\\\'\n",
    "        src += str(j)\n",
    "        src += '.bmp'\n",
    "        X[cnt] = img2vector(src)\n",
    "        Y[cnt] = i\n",
    "        cnt = cnt + 1\n",
    "\n",
    "for i in range(1,41):\n",
    "    for j in range(9,11):\n",
    "        src = 'C:\\\\Users\\\\93508\\\\Desktop\\\\ORL\\\\s'\n",
    "        src += str(i)\n",
    "        src += '\\\\'\n",
    "        src += str(j)\n",
    "        src += '.bmp'\n",
    "        X[cnt] = img2vector(src)\n",
    "        Y[cnt] = i\n",
    "        cnt = cnt + 1\n",
    "        \n",
    "\n",
    "Max_Point = 0\n",
    "final_n = 0\n",
    "final_C = 0\n",
    "final_gamma = 0\n",
    "final_degree = 0\n",
    "final_coef0 = 0\n",
    "for n in range(5,21):\n",
    "    \n",
    "    lda = LDA(n_components = n)\n",
    "    newX = lda.fit_transform(X,Y)\n",
    "\n",
    "    x_test = newX[320:400,:].astype(int)\n",
    "    y_test = Y[320:400].astype(int)\n",
    "    x_train = newX[0:320,:].astype(int)\n",
    "    y_train = Y[0:320].astype(int)\n",
    "\n",
    "    C = np.power(10, np.arange(5)).astype(int)\n",
    "    params = {'C': C,'solver':['liblinear']}\n",
    "\n",
    "    LR = GridSearchCV(LogisticRegression(), params, scoring = \"f1_macro\",cv = 5)\n",
    "\n",
    "    LR.fit(x_train,y_train)\n",
    "\n",
    "    cur_point = LR.best_score_\n",
    "\n",
    "    if cur_point > Max_Point:\n",
    "        Max_Point = cur_point\n",
    "        final_n = n\n",
    "        final_C = LR.best_params_['C']\n",
    "        \n",
    "\n",
    "print(\"\\nLDA的超参数n_components的最优解为: %d\\n\" %final_n)\n",
    "print(\"逻辑回归的超参数C的最优解为: %d\\n\" %final_C)\n",
    "y_predict = LR.predict(x_test)\n",
    "accuracy = accuracy_score(y_predict, y_test)\n",
    "print(\"测试集预测正确率为: %.2f%%\\n\" %(accuracy*100))\n",
    "print(\"最优超参数模型的评分为: %.2f\\n\" %Max_Point)\n",
    "print(\"测试集的预测分类报告如下所示：\\n\\n\")\n",
    "print(classification_report(y_test, y_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA+决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LDA的超参数n_components的最优解为: 15\n",
      "\n",
      "决策树的超参数max_depth的最优解为: 40 超参数min_samples_split的最优解为: 4 超参数min_samples_leaf的最优解为: 1\n",
      "\n",
      "测试集预测正确率为: 85.00%\n",
      "\n",
      "最优超参数模型的评分为: 0.81\n",
      "\n",
      "测试集的预测分类报告如下所示：\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      0.50      0.67         2\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       0.67      1.00      0.80         2\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       0.67      1.00      0.80         2\n",
      "           8       1.00      1.00      1.00         2\n",
      "           9       1.00      1.00      1.00         2\n",
      "          10       1.00      1.00      1.00         2\n",
      "          11       1.00      1.00      1.00         2\n",
      "          12       1.00      1.00      1.00         2\n",
      "          13       1.00      1.00      1.00         2\n",
      "          14       1.00      1.00      1.00         2\n",
      "          15       0.00      0.00      0.00         2\n",
      "          16       1.00      1.00      1.00         2\n",
      "          17       1.00      1.00      1.00         2\n",
      "          18       1.00      0.50      0.67         2\n",
      "          19       0.33      0.50      0.40         2\n",
      "          20       1.00      1.00      1.00         2\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       1.00      1.00      1.00         2\n",
      "          23       1.00      1.00      1.00         2\n",
      "          24       1.00      1.00      1.00         2\n",
      "          25       1.00      1.00      1.00         2\n",
      "          26       1.00      1.00      1.00         2\n",
      "          27       1.00      0.50      0.67         2\n",
      "          28       0.50      0.50      0.50         2\n",
      "          29       1.00      0.50      0.67         2\n",
      "          30       0.67      1.00      0.80         2\n",
      "          31       1.00      1.00      1.00         2\n",
      "          32       0.50      0.50      0.50         2\n",
      "          33       1.00      1.00      1.00         2\n",
      "          34       1.00      1.00      1.00         2\n",
      "          35       0.67      1.00      0.80         2\n",
      "          36       1.00      0.50      0.67         2\n",
      "          37       0.67      1.00      0.80         2\n",
      "          38       1.00      1.00      1.00         2\n",
      "          39       0.67      1.00      0.80         2\n",
      "          40       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.85        80\n",
      "   macro avg       0.86      0.85      0.84        80\n",
      "weighted avg       0.86      0.85      0.84        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def img2vector(filename):\n",
    "    img = mpimg.imread(filename) \n",
    "    return img.reshape(1, -1)\n",
    "\n",
    "X = np.zeros((400,10304),dtype = int)\n",
    "Y = np.zeros(400,dtype = int)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(1,41):\n",
    "    for j in range(1,9):\n",
    "        src = 'C:\\\\Users\\\\93508\\\\Desktop\\\\ORL\\\\s'\n",
    "        src += str(i)\n",
    "        src += '\\\\'\n",
    "        src += str(j)\n",
    "        src += '.bmp'\n",
    "        X[cnt] = img2vector(src)\n",
    "        Y[cnt] = i\n",
    "        cnt = cnt + 1\n",
    "\n",
    "for i in range(1,41):\n",
    "    for j in range(9,11):\n",
    "        src = 'C:\\\\Users\\\\93508\\\\Desktop\\\\ORL\\\\s'\n",
    "        src += str(i)\n",
    "        src += '\\\\'\n",
    "        src += str(j)\n",
    "        src += '.bmp'\n",
    "        X[cnt] = img2vector(src)\n",
    "        Y[cnt] = i\n",
    "        cnt = cnt + 1\n",
    "        \n",
    "\n",
    "Max_Point = 0\n",
    "final_n = 0\n",
    "final_max_depth = 0\n",
    "final_min_samples_split = 0\n",
    "final_min_samples_leaf = 0\n",
    "\n",
    "for n in range(5,21):\n",
    "    \n",
    "    lda = LDA(n_components = n)\n",
    "    newX = lda.fit_transform(X,Y)\n",
    "\n",
    "    x_test = newX[320:400,:]\n",
    "    y_test = Y[320:400]\n",
    "    x_train = newX[0:320,:]\n",
    "    y_train = Y[0:320]\n",
    "\n",
    "    params = {'max_depth': [40,60,80],'min_samples_split':[2,4,6],'min_samples_leaf': [1,3,5]}\n",
    "\n",
    "    dectree = GridSearchCV(DecisionTreeClassifier(), params, scoring = \"f1_macro\",cv = 5)\n",
    "\n",
    "    dectree.fit(x_train,y_train)\n",
    "\n",
    "    cur_point = dectree.best_score_\n",
    "\n",
    "    if cur_point > Max_Point:\n",
    "        Max_Point = cur_point\n",
    "        final_n = n\n",
    "        final_max_depth = dectree.best_params_['max_depth']\n",
    "        final_min_samples_split = dectree.best_params_['min_samples_split']\n",
    "        final_min_samples_leaf = dectree.best_params_['min_samples_leaf']\n",
    "        \n",
    "\n",
    "print(\"\\nLDA的超参数n_components的最优解为: %d\\n\" %final_n)\n",
    "print(\"决策树的超参数max_depth的最优解为: %d 超参数min_samples_split的最优解为: %d 超参数min_samples_leaf的最优解为: %d\\n\" %(final_max_depth,final_min_samples_split,final_min_samples_leaf))\n",
    "y_predict = dectree.predict(x_test)\n",
    "accuracy = accuracy_score(y_predict, y_test)\n",
    "print(\"测试集预测正确率为: %.2f%%\\n\" %(accuracy*100))\n",
    "print(\"最优超参数模型的评分为: %.2f\\n\" %Max_Point)\n",
    "print(\"测试集的预测分类报告如下所示：\\n\\n\")\n",
    "print(classification_report(y_test, y_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA+随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LDA的超参数n_components的最优解为: 12\n",
      "\n",
      "随机森林的超参数n_estimators的最优解为: 300 超参数max_depth的最优解为: 20\n",
      "\n",
      "测试集预测正确率为: 100.00%\n",
      "\n",
      "最优超参数模型的评分为: 1.00\n",
      "\n",
      "测试集的预测分类报告如下所示：\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       1.00      1.00      1.00         2\n",
      "           9       1.00      1.00      1.00         2\n",
      "          10       1.00      1.00      1.00         2\n",
      "          11       1.00      1.00      1.00         2\n",
      "          12       1.00      1.00      1.00         2\n",
      "          13       1.00      1.00      1.00         2\n",
      "          14       1.00      1.00      1.00         2\n",
      "          15       1.00      1.00      1.00         2\n",
      "          16       1.00      1.00      1.00         2\n",
      "          17       1.00      1.00      1.00         2\n",
      "          18       1.00      1.00      1.00         2\n",
      "          19       1.00      1.00      1.00         2\n",
      "          20       1.00      1.00      1.00         2\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       1.00      1.00      1.00         2\n",
      "          23       1.00      1.00      1.00         2\n",
      "          24       1.00      1.00      1.00         2\n",
      "          25       1.00      1.00      1.00         2\n",
      "          26       1.00      1.00      1.00         2\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       1.00      1.00      1.00         2\n",
      "          29       1.00      1.00      1.00         2\n",
      "          30       1.00      1.00      1.00         2\n",
      "          31       1.00      1.00      1.00         2\n",
      "          32       1.00      1.00      1.00         2\n",
      "          33       1.00      1.00      1.00         2\n",
      "          34       1.00      1.00      1.00         2\n",
      "          35       1.00      1.00      1.00         2\n",
      "          36       1.00      1.00      1.00         2\n",
      "          37       1.00      1.00      1.00         2\n",
      "          38       1.00      1.00      1.00         2\n",
      "          39       1.00      1.00      1.00         2\n",
      "          40       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        80\n",
      "   macro avg       1.00      1.00      1.00        80\n",
      "weighted avg       1.00      1.00      1.00        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def img2vector(filename):\n",
    "    img = mpimg.imread(filename) \n",
    "    return img.reshape(1, -1)\n",
    "\n",
    "X = np.zeros((400,10304),dtype = int)\n",
    "Y = np.zeros(400,dtype = int)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(1,41):\n",
    "    for j in range(1,9):\n",
    "        src = 'C:\\\\Users\\\\93508\\\\Desktop\\\\ORL\\\\s'\n",
    "        src += str(i)\n",
    "        src += '\\\\'\n",
    "        src += str(j)\n",
    "        src += '.bmp'\n",
    "        X[cnt] = img2vector(src)\n",
    "        Y[cnt] = i\n",
    "        cnt = cnt + 1\n",
    "\n",
    "for i in range(1,41):\n",
    "    for j in range(9,11):\n",
    "        src = 'C:\\\\Users\\\\93508\\\\Desktop\\\\ORL\\\\s'\n",
    "        src += str(i)\n",
    "        src += '\\\\'\n",
    "        src += str(j)\n",
    "        src += '.bmp'\n",
    "        X[cnt] = img2vector(src)\n",
    "        Y[cnt] = i\n",
    "        cnt = cnt + 1\n",
    "        \n",
    "\n",
    "Max_Point = 0\n",
    "final_n = 0\n",
    "final_n_estimators = 0\n",
    "final_max_depth = 0\n",
    "\n",
    "for n in range(5,21):\n",
    "    \n",
    "    lda = LDA(n_components = n)\n",
    "    newX = lda.fit_transform(X,Y)\n",
    "\n",
    "    x_test = newX[320:400,:]\n",
    "    y_test = Y[320:400]\n",
    "    x_train = newX[0:320,:]\n",
    "    y_train = Y[0:320]\n",
    "\n",
    "    params = {'n_estimators':[100,300,500],'max_depth':[10,20,30]}\n",
    "\n",
    "    rndtree = GridSearchCV(RandomForestClassifier(), params, scoring = \"f1_macro\",cv = 5)\n",
    "\n",
    "    rndtree.fit(x_train,y_train)\n",
    "\n",
    "    cur_point = rndtree.best_score_\n",
    "\n",
    "    if cur_point > Max_Point:\n",
    "        Max_Point = cur_point\n",
    "        final_n = n\n",
    "        final_n_estimators = rndtree.best_params_['n_estimators']\n",
    "        final_max_depth = rndtree.best_params_['max_depth']\n",
    "        \n",
    "\n",
    "print(\"\\nLDA的超参数n_components的最优解为: %d\\n\" %final_n)\n",
    "print(\"随机森林的超参数n_estimators的最优解为: %d 超参数max_depth的最优解为: %d\\n\" %(final_n_estimators,final_max_depth))\n",
    "y_predict = rndtree.predict(x_test)\n",
    "accuracy = accuracy_score(y_predict, y_test)\n",
    "print(\"测试集预测正确率为: %.2f%%\\n\" %(accuracy*100))\n",
    "print(\"最优超参数模型的评分为: %.2f\\n\" %Max_Point)\n",
    "print(\"测试集的预测分类报告如下所示：\\n\\n\")\n",
    "print(classification_report(y_test, y_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA+adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LDA的超参数n_components的最优解为: 12\n",
      "\n",
      "adaboost的超参数n_estimators的最优解为: 500 超参数learning_rate的最优解为: 0.3\n",
      "\n",
      "测试集预测正确率为: 71.25%\n",
      "\n",
      "最优超参数模型的评分为: 0.64\n",
      "\n",
      "测试集的预测分类报告如下所示：\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      0.50      0.67         2\n",
      "           3       1.00      0.50      0.67         2\n",
      "           4       0.67      1.00      0.80         2\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       1.00      1.00      1.00         2\n",
      "           9       0.67      1.00      0.80         2\n",
      "          10       1.00      0.50      0.67         2\n",
      "          11       1.00      0.50      0.67         2\n",
      "          12       1.00      1.00      1.00         2\n",
      "          13       0.33      1.00      0.50         2\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       1.00      0.50      0.67         2\n",
      "          16       1.00      1.00      1.00         2\n",
      "          17       1.00      1.00      1.00         2\n",
      "          18       0.00      0.00      0.00         2\n",
      "          19       1.00      0.50      0.67         2\n",
      "          20       1.00      1.00      1.00         2\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       0.40      1.00      0.57         2\n",
      "          23       0.00      0.00      0.00         2\n",
      "          24       1.00      1.00      1.00         2\n",
      "          25       0.22      1.00      0.36         2\n",
      "          26       1.00      1.00      1.00         2\n",
      "          27       0.67      1.00      0.80         2\n",
      "          28       0.33      0.50      0.40         2\n",
      "          29       1.00      1.00      1.00         2\n",
      "          30       1.00      0.50      0.67         2\n",
      "          31       1.00      1.00      1.00         2\n",
      "          32       1.00      1.00      1.00         2\n",
      "          33       1.00      1.00      1.00         2\n",
      "          34       1.00      0.50      0.67         2\n",
      "          35       1.00      1.00      1.00         2\n",
      "          36       1.00      0.50      0.67         2\n",
      "          37       0.50      0.50      0.50         2\n",
      "          38       0.50      1.00      0.67         2\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.71        80\n",
      "   macro avg       0.73      0.71      0.69        80\n",
      "weighted avg       0.73      0.71      0.69        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def img2vector(filename):\n",
    "    img = mpimg.imread(filename) \n",
    "    return img.reshape(1, -1)\n",
    "\n",
    "X = np.zeros((400,10304),dtype = int)\n",
    "Y = np.zeros(400,dtype = int)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(1,41):\n",
    "    for j in range(1,9):\n",
    "        src = 'C:\\\\Users\\\\93508\\\\Desktop\\\\ORL\\\\s'\n",
    "        src += str(i)\n",
    "        src += '\\\\'\n",
    "        src += str(j)\n",
    "        src += '.bmp'\n",
    "        X[cnt] = img2vector(src)\n",
    "        Y[cnt] = i\n",
    "        cnt = cnt + 1\n",
    "\n",
    "for i in range(1,41):\n",
    "    for j in range(9,11):\n",
    "        src = 'C:\\\\Users\\\\93508\\\\Desktop\\\\ORL\\\\s'\n",
    "        src += str(i)\n",
    "        src += '\\\\'\n",
    "        src += str(j)\n",
    "        src += '.bmp'\n",
    "        X[cnt] = img2vector(src)\n",
    "        Y[cnt] = i\n",
    "        cnt = cnt + 1\n",
    "        \n",
    "\n",
    "Max_Point = 0\n",
    "final_n = 0\n",
    "final_n_estimators = 0\n",
    "final_learning_rate = 0\n",
    "\n",
    "for n in range(5,21):\n",
    "    \n",
    "    lda = LDA(n_components = n)\n",
    "    newX = lda.fit_transform(X,Y)\n",
    "\n",
    "    x_test = newX[320:400,:]\n",
    "    y_test = Y[320:400]\n",
    "    x_train = newX[0:320,:]\n",
    "    y_train = Y[0:320]\n",
    "\n",
    "    params = {'n_estimators':[100,300,500],'learning_rate':[0.3,0.6,0.9]}\n",
    "\n",
    "    AB = GridSearchCV(AdaBoostClassifier(), params, scoring = \"f1_macro\",cv = 5)\n",
    "\n",
    "    AB.fit(x_train,y_train)\n",
    "\n",
    "    cur_point = AB.best_score_\n",
    "\n",
    "    if cur_point > Max_Point:\n",
    "        Max_Point = cur_point\n",
    "        final_n = n\n",
    "        final_n_estimators = AB.best_params_['n_estimators']\n",
    "        final_learning_rate = AB.best_params_['learning_rate']\n",
    "        \n",
    "\n",
    "print(\"\\nLDA的超参数n_components的最优解为: %d\\n\" %final_n)\n",
    "print(\"adaboost的超参数n_estimators的最优解为: %d 超参数learning_rate的最优解为: %.1f\\n\" %(final_n_estimators,final_learning_rate))\n",
    "y_predict = AB.predict(x_test)\n",
    "accuracy = accuracy_score(y_predict, y_test)\n",
    "print(\"测试集预测正确率为: %.2f%%\\n\" %(accuracy*100))\n",
    "print(\"最优超参数模型的评分为: %.2f\\n\" %Max_Point)\n",
    "print(\"测试集的预测分类报告如下所示：\\n\\n\")\n",
    "print(classification_report(y_test, y_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA+神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LDA的超参数n_components的最优解为: 13\n",
      "\n",
      "神经网络的超参数hidden_layer_sizes的最优解为: 50 超参数alpha的最优解为: 0.001000 超参数max_iter的最优解为: 500\n",
      "\n",
      "测试集预测正确率为: 98.75%\n",
      "\n",
      "最优超参数模型的评分为: 1.00\n",
      "\n",
      "测试集的预测分类报告如下所示：\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       0.67      1.00      0.80         2\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       1.00      1.00      1.00         2\n",
      "           9       1.00      1.00      1.00         2\n",
      "          10       1.00      1.00      1.00         2\n",
      "          11       1.00      1.00      1.00         2\n",
      "          12       1.00      1.00      1.00         2\n",
      "          13       1.00      1.00      1.00         2\n",
      "          14       1.00      1.00      1.00         2\n",
      "          15       1.00      1.00      1.00         2\n",
      "          16       1.00      1.00      1.00         2\n",
      "          17       1.00      1.00      1.00         2\n",
      "          18       1.00      0.50      0.67         2\n",
      "          19       1.00      1.00      1.00         2\n",
      "          20       1.00      1.00      1.00         2\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       1.00      1.00      1.00         2\n",
      "          23       1.00      1.00      1.00         2\n",
      "          24       1.00      1.00      1.00         2\n",
      "          25       1.00      1.00      1.00         2\n",
      "          26       1.00      1.00      1.00         2\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       1.00      1.00      1.00         2\n",
      "          29       1.00      1.00      1.00         2\n",
      "          30       1.00      1.00      1.00         2\n",
      "          31       1.00      1.00      1.00         2\n",
      "          32       1.00      1.00      1.00         2\n",
      "          33       1.00      1.00      1.00         2\n",
      "          34       1.00      1.00      1.00         2\n",
      "          35       1.00      1.00      1.00         2\n",
      "          36       1.00      1.00      1.00         2\n",
      "          37       1.00      1.00      1.00         2\n",
      "          38       1.00      1.00      1.00         2\n",
      "          39       1.00      1.00      1.00         2\n",
      "          40       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.99        80\n",
      "   macro avg       0.99      0.99      0.99        80\n",
      "weighted avg       0.99      0.99      0.99        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def img2vector(filename):\n",
    "    img = mpimg.imread(filename) \n",
    "    return img.reshape(1, -1)\n",
    "\n",
    "X = np.zeros((400,10304),dtype = int)\n",
    "Y = np.zeros(400,dtype = int)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(1,41):\n",
    "    for j in range(1,9):\n",
    "        src = 'C:\\\\Users\\\\93508\\\\Desktop\\\\ORL\\\\s'\n",
    "        src += str(i)\n",
    "        src += '\\\\'\n",
    "        src += str(j)\n",
    "        src += '.bmp'\n",
    "        X[cnt] = img2vector(src)\n",
    "        Y[cnt] = i\n",
    "        cnt = cnt + 1\n",
    "\n",
    "for i in range(1,41):\n",
    "    for j in range(9,11):\n",
    "        src = 'C:\\\\Users\\\\93508\\\\Desktop\\\\ORL\\\\s'\n",
    "        src += str(i)\n",
    "        src += '\\\\'\n",
    "        src += str(j)\n",
    "        src += '.bmp'\n",
    "        X[cnt] = img2vector(src)\n",
    "        Y[cnt] = i\n",
    "        cnt = cnt + 1\n",
    "        \n",
    "\n",
    "Max_point = 0\n",
    "final_n = 0\n",
    "final_hidden_layer_sizes = 0\n",
    "final_alpha = 0\n",
    "final_max_iter = 0\n",
    "\n",
    "for n in range(5,21):\n",
    "    \n",
    "    lda = LDA(n_components = n)\n",
    "    newX = lda.fit_transform(X,Y)\n",
    "\n",
    "    x_test = newX[320:400,:]\n",
    "    y_test = Y[320:400]\n",
    "    x_train = newX[0:320,:]\n",
    "    y_train = Y[0:320]\n",
    "\n",
    "    \n",
    "    mlp_clf__tuned_parameters = {'hidden_layer_sizes':[10,30,50],'alpha':[0.1,0.001,0.001],'max_iter':[100,300,500]}\n",
    "    \n",
    "    mlp = GridSearchCV(MLPClassifier(), mlp_clf__tuned_parameters, scoring = \"f1_macro\", cv = 5)\n",
    "    \n",
    "    mlp.fit(x_train,y_train)\n",
    "\n",
    "    cur_point = mlp.best_score_\n",
    "\n",
    "    if cur_point > Max_point:\n",
    "        Max_point = cur_point\n",
    "        final_n = n\n",
    "        final_hidden_layer_sizes = mlp.best_params_['hidden_layer_sizes']\n",
    "        final_alpha = mlp.best_params_['alpha']\n",
    "        final_max_iter = mlp.best_params_['max_iter']\n",
    "        \n",
    "\n",
    "print(\"\\nLDA的超参数n_components的最优解为: %d\\n\" %final_n)\n",
    "print(\"神经网络的超参数hidden_layer_sizes的最优解为: %d 超参数alpha的最优解为: %f 超参数max_iter的最优解为: %d\\n\" %(final_hidden_layer_sizes,final_alpha,final_max_iter))\n",
    "y_predict = mlp.predict(x_test)\n",
    "accuracy = accuracy_score(y_predict, y_test)\n",
    "print(\"测试集预测正确率为: %.2f%%\\n\" %(accuracy*100))\n",
    "print(\"最优超参数模型的评分为: %.2f\\n\" %Max_point)\n",
    "print(\"测试集的预测分类报告如下所示：\\n\\n\")\n",
    "print(classification_report(y_test, y_predict))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
